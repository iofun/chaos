{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello Python!'\n"
     ]
    }
   ],
   "source": [
    "print(b\"Hello Python!\") # could this represent a binary string?\n",
    "                        # what is the concept of binary string in pythonland?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git 2.19 Switch to the SHA-256 hash algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07621a3770d9965e8ba345b6a19b1f568f94d108bdd1aaa6ccf5125f547a5095'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha256(b\"unit mango 1\").hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a lot less elegant language in nearly every way but it has the data science libraries and a lot of them are pretty great so I kind of use it because it's the best we have but it's definitely not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope X is successful bacause the goal it is to be infinitely hackable and that's what I want, I want something where me and the people I do research with and my students can look at and change everything from top to bottom unfortunately with Python it's the opposite of that because pythons so slow it's extremely unhackable you get to a point where it's like okay from here on down at C so your debugger doesn't work in the same way your profiler dosn't work in the same way your build system doesn't work in the same way it's really not very hackable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a big gap in terms of our ability to innovate around recurrent neural networks and natural language processing because it's so slow the actual loop where we actually loop through words we have to do that whole thing in C so we actually can't innovate with the kernel the heart of that most important algorithm and it's just a huge problem and this happens all over the place so we hit research limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's just big gaps in like what people actually research on what people actually implement because of the programming language problem, it's kind of just too difficult to write things in C, a programming language like X should enable the easier input fooling around creative stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is just that we ignore Y but recently people have been starting to reinvent pieces of that and kind of create some interesting new directions in compiler technology because if you have to deal with the fact that I've got you know 10,000 threads and I have to synchronize between them all and I have to put my thing in to grid blocks and think about warps and all this stuff it's just it's just so much boilerplate to do that well you have to be a specialist at that and it's going to be a year's work to optimize that algorithm in that way but with things like tensor comprehensions and all these various projects which are all about saying let's let people create like domain-specific languages for tensor computations these are the kinds of things we do generally on the GPU for deep learning and then have a compiler which can optimize that tensor computation like do it block by block and do these bits in parallel directly acccessible thorugh X so that I could use X to kind of write those domain-specific languages and hopefully we'll get them X CUDA kernels written in a very expressive and concise way that looks a bit like Lua in Erlang and then X layers on top of that and a nice javascript UI, it does all eventually boil down to CUDA and NVIDIA GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you comment in whichever you want to comment on?\n",
    "\n",
    "I'm not that hopeful that Python will develop into a sort of high concurrency high parallelism language that's sort of the way the language is designed the way most users use the language the way the language is implemented all make that a pretty unlikely future... I think async IO is a special case because it sort of allows overlapping IO and only IO and that is a sort of best practice of supporting very high throughput IO many connections per second I'm not worried about that I think async IO will evolve, parallel computing I think that Python is not the language for that there are ways to work around it but you can't expect to write an algorithm in Python and have a compiler automatically parallelize that, what you can do is use a package like numpy and they're a bunch of other very powerful packages that uuse all the CPUs available because you tell the package here's the data here's the abstract operation to apply over it go at it and then we're back in the C++ world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in terms of packaging? can you comment in the future of packaging?\n",
    "\n",
    "Packaging has alway been my least favorite topic it's a really tough problem because the OS and the platform want to own packaging and several languages like node JavaScript and Ruby and Python all have their own packaging solutions that only work within the ecosystem of that language well what should you use that is a tough problem my own approach is I use the system packaging system to install Python and I use the Python packaging system then to install third party Python packages that's what most people do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten years ago packaging was terrible now pip is the present and the future there is a separate ecosystem for numerial and scientific Python, Python based on anaconda those two can live together I don't think there is a need for more than that so that's packaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
